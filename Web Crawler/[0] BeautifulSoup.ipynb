{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[1.] [Python 使用 Beautiful Soup 抓取與解析網頁資料，開發網路爬蟲教學](https://blog.gtwang.org/programming/python-beautiful-soup-module-scrape-web-pages-tutorial/)\n",
    "\n",
    "[2.] [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "[3.] [python 3 筆記 - 利用 urllib 來存取網頁](http://beanobody.blogspot.com/2015/12/python-3-urllib.html)\n",
    "***\n",
    "\n",
    "[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) 是一個 Python 的函式庫模組，可以讓開發者僅須撰寫非常少量的程式碼，就可以快速解析網頁 HTML 碼，從中翠取出使用者有興趣的資料、去蕪存菁，降低網路爬蟲程式的開發門檻、加快程式撰寫速度。\n",
    "\n",
    "***\n",
    "\n",
    "## Beautiful Soup 基本用法\n",
    "\n",
    "Beautiful Soup 的運作方式就是讀取 HTML 原始碼，自動進行解析並產生一個 BeautifulSoup 物件，此物件中包含了整個 HTML 文件的結構樹，有了這個結構樹之後，就可以輕鬆找出任何有興趣的資料了。\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "以下是一個簡單的小程式，示範如何使用 **Beautiful Soup** 模組解析原始的 **HTML** 程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入 Beautiful Soup 模組\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 原始 HTML 程式碼\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>Hello World</title></head>\n",
    "<body><h2>Test Header</h2>\n",
    "<p>This is a test.</p>\n",
    "<a id=\"link1\" href=\"/my_link1\">Link 1</a>\n",
    "<a id=\"link2\" href=\"/my_link2\">Link 2</a>\n",
    "<p>Hello, <b class=\"boldtext\">Bold Text</b></p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# 以 Beautiful Soup 解析 HTML 程式碼\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡的 **soup** 就是解析完成後，所產生的結構樹物件，接下來所有資料的搜尋、萃取等操作都會透過這個物件來進行。\n",
    "\n",
    "***\n",
    "\n",
    "首先我們可以將完整個 **HTML** 結構經過排版後輸出，觀察整份文件的輪廓："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Hello World\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h2>\n",
      "   Test Header\n",
      "  </h2>\n",
      "  <p>\n",
      "   This is a test.\n",
      "  </p>\n",
      "  <a href=\"/my_link1\" id=\"link1\">\n",
      "   Link 1\n",
      "  </a>\n",
      "  <a href=\"/my_link2\" id=\"link2\">\n",
      "   Link 2\n",
      "  </a>\n",
      "  <p>\n",
      "   Hello,\n",
      "   <b class=\"boldtext\">\n",
      "    Bold Text\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 輸出排版後的 HTML 程式碼\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得節點文字內容\n",
    "若要輸出網頁標題的 HTML 標籤，可以直接指定網頁標題標籤的名稱（**title**），即可將該標籤的節點抓出來："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Hello World</title>\n"
     ]
    }
   ],
   "source": [
    "# 網頁標題 HTML 標籤\n",
    "title_tag = soup.title\n",
    "print(title_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML 標籤節點的文字內容，可以透過 **string** 屬性存取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(title_tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜尋節點\n",
    " - 我們可以使用 **find_all** 找出所有特定的 HTML 標籤節點\n",
    " - 再以 Python 的迴圈來依序輸出每個超連結的文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>,\n",
       " <a href=\"/my_link2\" id=\"link2\">Link 2</a>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有的超連結\n",
    "a_tags = soup.find_all('a')\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取出節點屬性\n",
    " - 若要取出 HTML 節點的各種屬性，可以使用 **get**\n",
    " - 例如輸出每個超連結的網址（href 屬性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1\n",
      "Link 2\n"
     ]
    }
   ],
   "source": [
    "for tag in a_tags:\n",
    "  # 輸出超連結的文字\n",
    "  print(tag.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/my_link1\n",
      "/my_link2\n"
     ]
    }
   ],
   "source": [
    "for tag in a_tags:\n",
    "  # 輸出超連結網址\n",
    "  print(tag.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同時搜尋多種標籤\n",
    "若要同時搜尋多種 HTML 標籤，可以使用 list 來指定所有的要列出的 HTML 標籤名稱："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>, <a href=\"/my_link2\" id=\"link2\">Link 2</a>, <b class=\"boldtext\">Bold Text</b>]\n"
     ]
    }
   ],
   "source": [
    "# 搜尋所有超連結與粗體字\n",
    "tags = soup.find_all([\"a\", \"b\"]) # 可以使用 list \n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 限制搜尋節點數量\n",
    " - **find_all** 預設會輸出所有符合條件的節點，\n",
    " - 但若是遇到節點數量很多的時候，就會需要比較久的計算時間\n",
    " - 如果我們不需要所有符合條件的節點，可以用 **limit** 參數指定搜尋節點數量的上限值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>, <a href=\"/my_link2\" id=\"link2\">Link 2</a>]\n"
     ]
    }
   ],
   "source": [
    "# 限制搜尋結果數量\n",
    "tags = soup.find_all([\"a\", \"b\"], limit=2)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果只需要抓出第一個符合條件的節點，可以直接使用 find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/my_link1\" id=\"link1\">Link 1</a>\n"
     ]
    }
   ],
   "source": [
    "# 只抓出第一個符合條件的節點\n",
    "a_tag = soup.find(\"a\")\n",
    "print(a_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遞迴搜尋\n",
    "\n",
    "預設的狀況下，find_all 會以遞迴的方式尋找所有的子節點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>Hello World</title>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 預設會以遞迴搜尋\n",
    "soup.html.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要限制 find_all 只找尋次一層的子節點，可以加上 recursive=False 關閉遞迴搜尋功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不使用遞迴搜尋，僅尋找次一層的子節點\n",
    "soup.html.find_all(\"title\", recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以 HTML 屬性搜尋\n",
    " - 我們也可以根據網頁 HTML 元素的屬性來萃取指定的 HTML 節點\n",
    " - 例如搜尋 id 屬性為 link2 的節點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/my_link2\" id=\"link2\">Link 2</a>\n"
     ]
    }
   ],
   "source": [
    "# 根據 id 搜尋\n",
    "link2_tag = soup.find(id='link2')\n",
    "print(link2_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 我們可以結合 HTML 節點的名稱與屬性進行更精確的搜尋\n",
    " - 例如搜尋 href 屬性為 **/my_link1** 的 a 節點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>]\n"
     ]
    }
   ],
   "source": [
    "# 搜尋 href 屬性為 /my_link1 的 a 節點\n",
    "a_tag = soup.find_all(\"a\", href=\"/my_link1\")\n",
    "print(a_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規表示法搜尋屬性\n",
    "\n",
    " - 搜尋屬性時，也可以使用**正規表示法**\n",
    " - 例如以正規表示法比對超連結網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>, <a href=\"/my_link2\" id=\"link2\">Link 2</a>]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 以正規表示法比對超連結網址\n",
    "links = soup.find_all(href = re.compile(\"^/my_link\\d\"))\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們也可以同時使用多個屬性的條件進行篩選："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>]\n"
     ]
    }
   ],
   "source": [
    "# 以多個屬性條件來篩選\n",
    "link = soup.find_all(href = re.compile(\"^/my_link\\d\"), id=\"link1\")\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 **HTML5** 中有一些屬性名稱若直接寫在 Python 的參數中會有一些問題，例如 data-* 這類的屬性直接寫的話，就會產生錯誤訊息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-19-ee1f74febb50>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-ee1f74febb50>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    data_soup.find_all(data-foo=\"value\")\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "data_soup = BeautifulSoup('<div data-foo=\"value\">foo!</div>', 'html.parser')\n",
    "\n",
    "# 錯誤的用法\n",
    "data_soup.find_all(data-foo=\"value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 遇到這種狀況，可以**把屬性的名稱與值放進一個 dictionary** 中\n",
    " - 再將此 dictionary 指定給 attrs 參數即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1fc1b2edbae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 正確的用法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data-foo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"value\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_soup' is not defined"
     ]
    }
   ],
   "source": [
    "# 正確的用法\n",
    "data_soup.find_all(attrs={\"data-foo\": \"value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-de0a2e4b0d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_soup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_soup' is not defined"
     ]
    }
   ],
   "source": [
    "data_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 以 CSS 搜尋\n",
    "由於 class 是 Python 程式語言的保留字，所以 Beautiful Soup 改以 class_ 這個名稱代表 HTML 節點的 class 屬性，例如搜尋 class 為 boldtext 的 b 節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<b class=\"boldtext\">Bold Text</b>]\n"
     ]
    }
   ],
   "source": [
    "# 搜尋 class 為 boldtext 的 b 節點\n",
    "b_tag = soup.find_all(\"b\", class_=\"boldtext\")\n",
    "print(b_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSS 的 class 屬性也可以使用正規表示法搜尋：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<b class=\"boldtext\">Bold Text</b>]\n"
     ]
    }
   ],
   "source": [
    "# 以正規表示法搜尋 class 屬性\n",
    "b_tag = soup.find_all(class_=re.compile(\"^bold\"))\n",
    "print(b_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一個 HTML 標籤元素可以同時有多個 CSS 的 class 屬性值，而我們在以 class_ 比對時，只要其中一個 class 符合就算比對成功，例如：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "css_soup = BeautifulSoup('<p class=\"body strikeout\"></p>', 'html.parser')\n",
    "\n",
    "# 只要其中一個 class 符合就算比對成功\n",
    "p_tag = css_soup.find_all(\"p\", class_=\"strikeout\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可拿完整的 class 字串來進行比對："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "# 比對完整的 class 字串\n",
    "p_tag = css_soup.find_all(\"p\", class_=\"body strikeout\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不過如果多個 class 名稱排列順序不同時，就會失敗："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 若順序不同，則會失敗\n",
    "p_tag = css_soup.find_all(\"p\", class_=\"strikeout body\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遇到多個 CSS class 的狀況，建議改用 CSS 選擇器來篩選："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"body strikeout\"></p>]\n"
     ]
    }
   ],
   "source": [
    "# 使用 CSS 選擇器\n",
    "p_tag = css_soup.select(\"p.strikeout.body\")\n",
    "print(p_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以文字內容搜尋\n",
    "若要依據文字內容來搜尋特定的節點，可以使用 find_all 配合 string 參數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/my_link1\" id=\"link1\">Link One</a>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_html = \"\"\"\n",
    "<a id=\"link1\" href=\"/my_link1\">Link One</a>\n",
    "<a id=\"link2\" href=\"/my_link2\">Link Two</a>\n",
    "<a id=\"link3\" href=\"/my_link3\">Link Three</a>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(links_html, 'html.parser')\n",
    "\n",
    "# 搜尋文字為「Link One」的超連結\n",
    "soup.find_all(\"a\", string=\"Link One\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "亦可使用正規表示法批配文字內容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/my_link1\" id=\"link1\">Link One</a>,\n",
       " <a href=\"/my_link2\" id=\"link2\">Link Two</a>,\n",
       " <a href=\"/my_link3\" id=\"link3\">Link Three</a>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以正規表示法搜尋文字為「Link」開頭的超連結\n",
    "soup.find_all(\"a\", string=re.compile(\"^Link\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向上、向前與向後搜尋\n",
    " - 前面介紹的 find_all 都是向下搜尋子節點\n",
    " \n",
    " \n",
    " - 如果需要向上搜尋父節點的話，\n",
    " - 可以改用 **find_parents 或是 find_parent**\n",
    " - 它可讓我們以某個特定節點為起始點，向上搜尋父節點："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"my_par\">\n",
      "<a href=\"/my_link1\" id=\"link1\">Link 1</a>\n",
      "<a href=\"/my_link2\" id=\"link2\">Link 2</a>\n",
      "<a href=\"/my_link3\" id=\"link3\">Link 3</a>\n",
      "<a href=\"/my_link4\" id=\"link3\">Link 4</a>\n",
      "</p>]\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<body><p class=\"my_par\">\n",
    "<a id=\"link1\" href=\"/my_link1\">Link 1</a>\n",
    "<a id=\"link2\" href=\"/my_link2\">Link 2</a>\n",
    "<a id=\"link3\" href=\"/my_link3\">Link 3</a>\n",
    "<a id=\"link3\" href=\"/my_link4\">Link 4</a>\n",
    "</p></body>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "link2_tag = soup.find(id=\"link2\")\n",
    "\n",
    "# 往上層尋找 p 節點\n",
    "p_tag = link2_tag.find_parents(\"p\")\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 如果想要在在同一層往前尋找特定節點，\n",
    " - 則可用 **find_previous_siblings** 函數\n",
    " - 或是 **find_previous_sibling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link1\" id=\"link1\">Link 1</a>]\n"
     ]
    }
   ],
   "source": [
    "# 在同一層往前尋找 a 節點\n",
    "link_tag = link2_tag.find_previous_siblings(\"a\")\n",
    "print(link_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 如果想要在在同一層往後尋找特定節點，\n",
    " - 則可用 **find_next_siblings** 函數\n",
    " - 或是 **find_next_sibling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/my_link3\" id=\"link3\">Link 3</a>, <a href=\"/my_link4\" id=\"link3\">Link 4</a>]\n"
     ]
    }
   ],
   "source": [
    "# 在同一層往後尋找 a 節點\n",
    "link_tag = link2_tag.find_next_siblings(\"a\")\n",
    "print(link_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 網頁檔案\n",
    "如果我們想要用 Beautiful Soup 解析已經下載的 HTML 檔案，可以直接將開啟的檔案交給 BeautifulSoup 處理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://www.google.com/search?q=python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-26bddc9762bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 從檔案讀取 HTML 程式碼進行解析\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.google.com/search?q=python\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.google.com/search?q=python'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 從檔案讀取 HTML 程式碼進行解析\n",
    "with open(\"https://www.google.com/search?q=python\") as f:\n",
    "    soup = BeautifulSoup(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
